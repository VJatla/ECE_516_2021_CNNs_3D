{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_3D.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C60AJrFBKZV6","executionInfo":{"status":"ok","timestamp":1634409558906,"user_tz":360,"elapsed":630,"user":{"displayName":"Marios Pattichis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaHMdmkCY5FRwczUOtlyeojYLu7rZ1zrCc5FGqPw=s64","userId":"01883140544600178282"}},"outputId":"03a81283-340b-4f3e-9dca-500c92926809"},"source":["# Hardware information\n","!lscpu # CPU info\n","!free -h --si | awk  '/Mem:/{print $2}' # Memory info"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Architecture:        x86_64\n","CPU op-mode(s):      32-bit, 64-bit\n","Byte Order:          Little Endian\n","CPU(s):              2\n","On-line CPU(s) list: 0,1\n","Thread(s) per core:  2\n","Core(s) per socket:  1\n","Socket(s):           1\n","NUMA node(s):        1\n","Vendor ID:           GenuineIntel\n","CPU family:          6\n","Model:               79\n","Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n","Stepping:            0\n","CPU MHz:             2199.998\n","BogoMIPS:            4399.99\n","Hypervisor vendor:   KVM\n","Virtualization type: full\n","L1d cache:           32K\n","L1i cache:           32K\n","L2 cache:            256K\n","L3 cache:            56320K\n","NUMA node0 CPU(s):   0,1\n","Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","13G\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lwc1pJgSpmZP","executionInfo":{"status":"ok","timestamp":1634409565926,"user_tz":360,"elapsed":7022,"user":{"displayName":"Marios Pattichis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaHMdmkCY5FRwczUOtlyeojYLu7rZ1zrCc5FGqPw=s64","userId":"01883140544600178282"}},"outputId":"c1eb7910-5173-4973-f9e5-52b63fdf355b"},"source":["# Install required libraries\n","!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n","!pip install -q mediapy\n","!pip install -q scikit-video \n","\n","\n","# Mounting google colab drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","from google.colab.patches import cv2_imshow\n","\n","# Libraries\n","import time\n","import numpy as np\n","import sklearn as skl\n","import skvideo as skv\n","import cv2\n","from matplotlib import pyplot as plt\n","\n","# Torch modules\n","# PyTorch libraries and modules\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import *\n","from torchsummary import summary\n","\n","from sklearn.metrics import accuracy_score\n","\n","import pdb\n","import sys\n","import os\n","import mediapy as media\n","%matplotlib inline"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AJmTkn1Dsmo4","executionInfo":{"status":"ok","timestamp":1634409565927,"user_tz":360,"elapsed":18,"user":{"displayName":"Marios Pattichis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaHMdmkCY5FRwczUOtlyeojYLu7rZ1zrCc5FGqPw=s64","userId":"01883140544600178282"}},"outputId":"2c2bf14d-8f89-4d40-cb66-f4d38033c509"},"source":["# Making sure that the libraries are loaded from the same directory as the torch. This is important, avoids conflicts.\n","print(f\"Torch        : {torch.__path__}\")\n","print(f\"Scikit Learn : {skl.__path__}\")\n","print(f\"Scikit video : {skv.__path__}\")\n","print(f\"Numpy        : {np.__path__}\")\n","print(f\"OpenCV       : {cv2.__path__}\")"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Torch        : ['/usr/local/lib/python3.7/dist-packages/torch']\n","Scikit Learn : ['/usr/local/lib/python3.7/dist-packages/sklearn']\n","Scikit video : ['/usr/local/lib/python3.7/dist-packages/skvideo']\n","Numpy        : ['/usr/local/lib/python3.7/dist-packages/numpy']\n","OpenCV       : ['/usr/local/lib/python3.7/dist-packages/cv2']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WwPa4kExs1XE","executionInfo":{"status":"ok","timestamp":1634409565928,"user_tz":360,"elapsed":16,"user":{"displayName":"Marios Pattichis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaHMdmkCY5FRwczUOtlyeojYLu7rZ1zrCc5FGqPw=s64","userId":"01883140544600178282"}},"outputId":"eb5d1acc-47d6-4e75-954d-1bdd8f33077d"},"source":["# Checking GPU access\n","if not torch.cuda.is_available():\n","  print(\"GPU not available\")\n","else:\n","  print(\"GPU availability          : \", torch.cuda.is_available(),\n","      \"\\nTotal devices on the node : \", torch.cuda.device_count(),\n","      \"\\nCurrent selected device   : \", torch.cuda.current_device())"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU not available\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"id":"8GDfw5r5qVtW","executionInfo":{"status":"error","timestamp":1634409565936,"user_tz":360,"elapsed":21,"user":{"displayName":"Marios Pattichis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaHMdmkCY5FRwczUOtlyeojYLu7rZ1zrCc5FGqPw=s64","userId":"01883140544600178282"}},"outputId":"242e0ba7-2e94-4864-b28f-abcd5f63d5cd"},"source":["# Loading numpy writing/no-writing numpy arrays and displaying some samples. \n","#     Shape      = (158, 300, 100, 100, 1), correspoinding to (Samples, Frames, Height, Width, Channels)\n","os.chdir(\"/content/gdrive/MyDrive/CNN_3D\")\n","X = np.load(\"gray_X.npy\")\n","Y = np.load(\"gray_y.npy\")\n","\n","X_sample_first = X[0]  # First sample\n","X_sample_last = X[-1]\n","\n","# First sample\n","X_sample_first_rgb = np.repeat(X_sample_first, 3, axis=3)\n","media.show_video(X_sample_first_rgb, height=100, codec='gif', fps=30)\n","\n","# Last sample\n","X_sample_last_rgb = np.repeat(X_sample_last, 3, axis=3)\n","media.show_video(X_sample_last_rgb, height=100, codec='gif', fps=30)"],"execution_count":14,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-ae34310415e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading numpy writing/no-writing numpy arrays and displaying some samples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#     Shape      = (158, 300, 100, 100, 1), correspoinding to (Samples, Frames, Height, Width, Channels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/CNN_3D\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gray_X.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gray_y.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/CNN_3D'"]}]},{"cell_type":"code","metadata":{"id":"f-YRQGTIw73P","executionInfo":{"status":"aborted","timestamp":1634409565929,"user_tz":360,"elapsed":12,"user":{"displayName":"Marios Pattichis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaHMdmkCY5FRwczUOtlyeojYLu7rZ1zrCc5FGqPw=s64","userId":"01883140544600178282"}}},"source":["# Creating training and testing sets\n","X_train = X[0:120]\n","X_test = X[120:158]\n","\n","Y_train = Y[0:120]\n","Y_test  = Y[120:158]\n","Y_train = Y_train.reshape(-1,1)\n","Y_test = Y_test.reshape(-1,1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8s2-XoCJw-6-","executionInfo":{"status":"aborted","timestamp":1634409565930,"user_tz":360,"elapsed":13,"user":{"displayName":"Marios Pattichis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaHMdmkCY5FRwczUOtlyeojYLu7rZ1zrCc5FGqPw=s64","userId":"01883140544600178282"}}},"source":["# Reshape to match expectation of pytorch (N, C_in, D_in, H, W)\n","# Swap axes channels with depth\n","# NOTE: Reshape fucntion scrambled the image. So I used three swaps to get it \n","# to desired shape.\n","# Training set\n","X_train = np.swapaxes(X_train, 1, 4) # (N, D_in, H, W, C_in) -> (N, C_in, H, W, D_in)\n","X_train = np.swapaxes(X_train, 2, 4) # (N, C_in, H, W, D_in) -> (N, C_in, D_in, W, H)\n","X_train = np.swapaxes(X_train, 3, 4) # (N, C_in, D_in, W, H) -> (N, C_in, D_in, H, W)\n","\n","\n","X_test = np.swapaxes(X_test, 1, 4) # (N, D_in, H, W, C_in) -> (N, C_in, H, W, D_in)\n","X_test = np.swapaxes(X_test, 2, 4) # (N, C_in, H, W, D_in) -> (N, C_in, D_in, W, H)\n","X_test = np.swapaxes(X_test, 3, 4) # (N, C_in, D_in, W, H) -> (N, C_in, D_in, H, W)\n","\n","# Displaying to make sure the swapping worked\n","X_train_first_sample = X_train[0,0]  # (D_in, H, W)\n","X_train_first_sample_gray = np.expand_dims(X_train_first_sample, axis=3) # (D_in, H, W, C_in = 1) == gray\n","X_train_first_sample_rgb = np.repeat(X_train_first_sample_gray, 3, axis=3) # (D_in, H, W, C_in = 3) == rgb\n","media.show_video(X_train_first_sample_rgb, height=100, codec='gif', fps=30)\n","\n","# Displaying to make sure the swapping worked\n","X_test_last_sample = X_test[-1,0]  # (D_in, H, W)\n","X_test_last_sample_gray = np.expand_dims(X_test_last_sample, axis=3) # (D_in, H, W, C_in = 1) == gray\n","X_test_last_sample_rgb = np.repeat(X_test_last_sample_gray, 3, axis=3) # (D_in, H, W, C_in = 3) == rgb\n","media.show_video(X_test_last_sample_rgb, height=100, codec='gif', fps=30)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"93XnmAtl4SJp","executionInfo":{"status":"aborted","timestamp":1634409565931,"user_tz":360,"elapsed":14,"user":{"displayName":"Marios Pattichis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaHMdmkCY5FRwczUOtlyeojYLu7rZ1zrCc5FGqPw=s64","userId":"01883140544600178282"}}},"source":["# Loading numpy arrays to torch\n","X_train_torch = torch.from_numpy(X_train).float()\n","X_test_torch = torch.from_numpy(X_test).float()\n","\n","Y_train_torch = torch.from_numpy(Y_train).float()\n","Y_test_torch = torch.from_numpy(Y_test).float()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Y-uyabb4Vr5","executionInfo":{"status":"aborted","timestamp":1634409565932,"user_tz":360,"elapsed":15,"user":{"displayName":"Marios Pattichis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaHMdmkCY5FRwczUOtlyeojYLu7rZ1zrCc5FGqPw=s64","userId":"01883140544600178282"}}},"source":["# Creating training and testing loaders\n","batch_size = 4\n","\n","# Creating training and testing sets using pytorch DataSet class\n","train = torch.utils.data.TensorDataset(X_train_torch, Y_train_torch)\n","test = torch.utils.data.TensorDataset(X_test_torch, Y_test_torch)\n","\n","# Dataloader\n","train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = True)\n","test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oPicMfs24ZAC","executionInfo":{"status":"aborted","timestamp":1634409565933,"user_tz":360,"elapsed":16,"user":{"displayName":"Marios Pattichis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaHMdmkCY5FRwczUOtlyeojYLu7rZ1zrCc5FGqPw=s64","userId":"01883140544600178282"}}},"source":["# A simple 3D-CNN network\n","num_classes = 2\n","\n","# Create CNN Model\n","class CNNModel(nn.Module):\n","    def __init__(self):\n","        super(CNNModel, self).__init__()\n","        \n","        self.conv_layer1 = self._conv_layer_set(1, 2)\n","        self.conv_layer2 = self._conv_layer_set(2, 4)\n","        self.fc1 = nn.Linear(15972, 64)\n","        self.fc2 = nn.Linear(64, 1) # 1 for binary classification\n","        self.relu = nn.LeakyReLU()\n","        self.batch=nn.BatchNorm1d(64)\n","        self.drop=nn.Dropout(p=0.5)        \n","        \n","    def _conv_layer_set(self, in_c, out_c):\n","        conv_layer = nn.Sequential(\n","        nn.Conv3d(in_c, out_c, 3, stride=1, padding=1, padding_mode=\"zeros\"),\n","        nn.LeakyReLU(),\n","        nn.MaxPool3d((3, 3, 3)),\n","        )\n","        return conv_layer\n","    \n","\n","    def forward(self, x):\n","        # Set 1\n","        out = self.conv_layer1(x)\n","        out = self.conv_layer2(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc1(out)\n","        out = self.relu(out)\n","        out = self.batch(out)\n","        out = self.drop(out)\n","        out = self.fc2(out)\n","        \n","        return out\n","\n","#Definition of hyperparameters\n","num_epochs = 5\n","\n","# Create CNN\n","model = CNNModel()\n","# model.cuda()\n","\n","# Cross Entropy Loss \n","error =  nn.BCEWithLogitsLoss()\n","\n","# SGD Optimizer\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gXH5YpLT4ctg","executionInfo":{"status":"aborted","timestamp":1634409565934,"user_tz":360,"elapsed":16,"user":{"displayName":"Marios Pattichis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaHMdmkCY5FRwczUOtlyeojYLu7rZ1zrCc5FGqPw=s64","userId":"01883140544600178282"}}},"source":["# CNN model training\n","loss_list = []\n","test_accuracy_list = []\n","train_accuracy_list = []\n","stime = time.time()\n","for epoch in range(num_epochs):\n","    for i, (train, labels) in enumerate(train_loader):\n","        \n","        \n","        # Clear gradients\n","        optimizer.zero_grad()\n","        \n","        # Forward propagation\n","        outputs = model(train)\n","        \n","        # Calculate softmax and ross entropy loss\n","        loss = error(outputs, labels)\n","        \n","        \n","        # Calculating gradients\n","        loss.backward()\n","        \n","        # Update parameters\n","        optimizer.step()\n","        \n","            \n","    \n","    # Iterate through training dataset\n","    y_pred = []\n","    y_true = []\n","    with torch.no_grad():\n","      for images, labels in train_loader:\n","\n","          # Forward propagation\n","          outputs = model(images)\n","\n","          # Get predictions\n","\n","          predicted = torch.round(torch.sigmoid(outputs))\n","\n","          # Collect prediction and ground truth\n","          y_pred += predicted.detach().numpy().flatten().tolist()\n","          y_true += labels.flatten().numpy().tolist()\n","\n","      train_accuracy = round(accuracy_score(y_true, y_pred), 2)\n","\n","    \n","    # Iterate through test dataset\n","    y_pred = []\n","    y_true = []\n","    with torch.no_grad():\n","      for images, labels in test_loader:\n","\n","          # Forward propagation\n","          outputs = model(images)\n","\n","          # Get predictions\n","          predicted = torch.round(torch.sigmoid(outputs))\n","\n","          # Collect prediction and ground truth\n","          y_pred += predicted.detach().numpy().flatten().tolist()\n","          y_true += labels.flatten().numpy().tolist()\n","\n","    test_accuracy = round(accuracy_score(y_true, y_pred), 2)\n","\n","\n","    # store loss and iteration\n","    loss_list.append(loss.data)\n","    train_accuracy_list.append(train_accuracy)\n","    test_accuracy_list.append(test_accuracy)\n","\n","    print('Epoch: {}  Train Loss: {}  Train Acc.: {} Test Acc.: {}'.format(epoch, loss.data, train_accuracy, test_accuracy))\n","\n","etime = time.time()\n","dtime = etime-stime\n","print(f\"For {num_epochs} it took {dtime/60} minutes\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n6wNBK_E4iyW","executionInfo":{"status":"aborted","timestamp":1634409565935,"user_tz":360,"elapsed":17,"user":{"displayName":"Marios Pattichis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaHMdmkCY5FRwczUOtlyeojYLu7rZ1zrCc5FGqPw=s64","userId":"01883140544600178282"}}},"source":["# visualization loss \n","plt.plot(np.arange(0,num_epochs),loss_list)\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"CNN: Loss vs Epochs\")\n","plt.show()\n","\n","# visualization accuracy \n","plt.plot(np.arange(0,num_epochs), train_accuracy_list,color = \"red\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Training Accuracy\")\n","plt.title(\"CNN: Training Accuracy vs Epochs\")\n","plt.show()\n","\n","# visualization accuracy \n","plt.plot(np.arange(0,num_epochs),test_accuracy_list,color = \"red\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Testing Accuracy\")\n","plt.title(\"CNN: Testing Accuracy vs Epochs\")\n","plt.show()"],"execution_count":null,"outputs":[]}]}